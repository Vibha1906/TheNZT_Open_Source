# TheNZT - Multi-Agent Finance Query System

![TheNZT Logo](docs/images/TheNZT_Logo.png)

<p align="center">
  <a href="https://github.com/IAI-solution/TheNZT_Open_Source/stargazers">
    <img src="https://img.shields.io/github/stars/IAI-solution/TheNZT_Open_Source?style=social" alt="GitHub stars"/>
  </a>

  <a href="https://github.com/IAI-solution/TheNZT_Open_Source/network/members">
    <img src="https://img.shields.io/github/forks/IAI-solution/TheNZT_Open_Source?style=social" alt="GitHub forks"/>
  </a>
</p>

TheNZT is a powerful multi-agent finance query processing system designed to process and respond to finance-related queries efficiently. Leveraging advanced LLM multi-agent collaboration, it provides intelligent solutions for Finance, Company-specific, and Market-related queries.

## Table of Contents

- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
  - [Local Development Setup](#local-development-setup)
  - [Docker Setup](#docker-setup)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [API Documentation](#api-documentation)
- [Contributing](#contributing)
- [Troubleshooting](#troubleshooting)
- [License](#license)

## Features

- ğŸ¤– Multi-agent LLM collaboration for finance queries
- ğŸ“ˆ Real-time stock price and market data
- ğŸ¢ Company-specific financial analysis
- ğŸ“Š Market trend summarization
- ğŸ” Intelligent query processing
- ğŸš€ Fast and scalable architecture
- ğŸ¨ Modern React frontend with Next.js
- âš¡ High-performance FastAPI backend

## Architecture Overview
In this system we mainly have 3 agents:

### 1. Fast Agent (Lite)
#### Overview
The Fast Agent (Insight Agent) is an AI-powered assistant designed to deliver rapid, accurate insights on companies, markets, through a modular, multi-step architecture. It processes natural language queries using a system prompt to enforce tone and structure, routes them to specialized tools (e.g., company ticker resolution, stock data retrieval, news search, and search via APIs like Financial Modeling Prep), and generates clear, brand-aligned markdown responses with inline citations.

#### Workflow
1. **User Query:** The agent receives a natural language question (e.g., â€œWhy is Teslaâ€™s stock falling?â€).
2. **Prompt Formatting:** The system formats the query using a predefined instruction set governing tone, structure, tool use, citations, and safety.
3. **Routing Logic:** A control layer determines which tool(s) to trigger based on the queryâ€™s intent (e.g., finance, news).
4. **Tool Execution:** The chosen tool(s) fetch relevant data (e.g., ticker lookup, stock prices, news).
5. **Response Generation:** The LLM generates a clear, well-cited markdown response using all retrieved data.
6. **Output to User:** The final response is delivered, including inline sources, tables (if needed), and a polite, brand-aligned tone.

![Fast Agent Architecture](docs/architectures/images/fast_2.png)

### 2. Planner Agent (Core)

#### Overview
The Planner Agent (Core) architecture is a structured, multi-agent system that processes user queries through a fixed, sequential plan. Starting with the Query Intent Detector to validate relevance, the Planner Agent creates a multi-step strategy, reviewed by the Executor Agent, which is executed by specialized agents like Web Search, Social Media Scrape, Finance Data, Sentiment Analysis, and Data Comparison. The Response Generator compiles a comprehensive, user-friendly response, making this approach ideal for systematic handling of complex queries.

#### Agents Used
- **Query Intent Detector**: Validates the relevance of user queries.
- **Planner**: Creates a fixed, multi-step plan involving specialized agents.
- **Executor**: Reviews and finalizes the plan created by the Planner.
- **Web Search**: Retrieves information from web sources.
- **Social Media Scrape**: Gathers data from social media platforms.
- **Finance Data**: Collects and processes financial information.
- **Sentiment Analysis**: Analyzes the sentiment of collected data.
- **Data Comparison**: Compares data from multiple sources for consistency and accuracy.
- **Response Generator**: Compiles and formats the final response for the user.

![Planner Agent Architecture](docs/architectures/images/planner_agent.png)

#### Workflow
1. **Query Intake**: The user query is received and processed by the **Query Intent Detector** to ensure relevance.
2. **Plan Creation**: The validated query is sent to the **Planner Agent**, which generates a fixed, multi-step plan involving the appropriate specialized agents.
3. **Plan Review**: The **Executor Agent** reviews and finalizes the plan.
4. **Task Routing**: A **Task Router** (implied component) sequentially assigns tasks to the agents specified in the plan, such as **Web Search**, **Social Media Scrape**, **Finance Data**, **Coding**, **Sentiment Analysis**, and **Data Comparison**.
5. **Data Processing**: Each assigned agent collects and analyzes data according to its specialization.
6. **Response Generation**: The processed information is passed to the **Response Generator Agent**, which compiles and formats the final response.
7. **Response Delivery**: The final response is delivered to the user.

#### Key Characteristic
The Base Agent Architecture follows a **pre-defined, sequential plan** generated at the beginning of the process, ensuring a structured and systematic approach to handling user queries.

### 3. Reasoning Agent (Pro)

#### Overview
The Reasoning Agent (Pro) architecture is a dynamic, iterative system that efficiently handles user queries through adaptive task assignment. After the Query Intent Detector validates relevance, the Manager Agent analyzes the query and assigns tasks one at a time to specialized agents (Web Search, Social Media Scrape, or Finance Data), iterating based on incoming data until sufficient information is gathered. The Response Generator then crafts a tailored response, making this flexible system ideal for diverse, evolving queries.

#### Agents Used
- **Query Intent Detector**: Validates the relevance of the user query.
- **Manager Agent**: Analyzes the query and current state, assigns tasks to specialized agents, and orchestrates the workflow.
- **Web Search Agent**: Retrieves relevant information from web sources.
- **Social Media Scrape Agent**: Gathers data from social media platforms.
- **Finance Data Agent**: Collects and processes financial data.
- **Response Generator Agent**: Crafts the final response for the user.

![Reasoning Agent Architecture](docs/architectures/images/reasoning_agent.png)

#### Workflow
1. **Query Validation**: The user query is received and validated for relevance by the Query Intent Detector.
2. **Query Analysis**: The validated query is passed to the Manager Agent, which analyzes the query and the current state.
3. **Task Assignment**: The Manager Agent assigns a single task to the most appropriate specialized agent (Web Search, Social Media Scrape, Finance Data, or Coding) based on the query's requirements.
4. **Iterative Reasoning**: The Manager Agent receives the result from the specialized agent, reasons about the next best step, and assigns another task if necessary. This loop continues iteratively until sufficient information is gathered.
5. **Response Generation**: Once enough information is collected, the Manager Agent tasks the Response Generator Agent to create the final response.
6. **Response Delivery**: The final response is delivered to the user.

#### Key Characteristic
The system employs **dynamic, iterative reasoning** to make task decisions one at a time, adapting the process as new information is gathered, ensuring flexibility and efficiency in handling diverse queries.

## Prerequisites

Before you begin, ensure you have the following installed on your system:

- **Python 3.10+** - [Download Python](https://www.python.org/downloads/)
- **Node.js 16+** and **npm** - [Download Node.js](https://nodejs.org/)
- **Git** - [Download Git](https://git-scm.com/downloads)
- **Docker & Docker Compose** (optional, for containerized setup) - [Download Docker](https://www.docker.com/get-started)

## Installation

### Local Development Setup

#### 1. Clone the Repository

```bash
git clone git@github.com:IAI-solution/TheNZT_Open_Source.git
cd TheNZT_Open_Source
```

#### 2. Environment Configuration

Create a `.env` file in the **project root** with your API keys (check .env.example):

```env
# Required API Keys
-GEMINI_API_KEY=your_gemini_api_key_here
-TAVILY_API_KEY=your_tavily_api_key_here
-FMP_API_KEY=your_fmp_api_key_here


# Database Configuration
MONGO_URI=

# Redis Configuration

REDIS_HOST=
REDIS_PORT=
REDIS_USERNAME=
REDIS_PASSWORD=


# Frontend Configuration

NEXT_PUBLIC_BASE_URL=http://localhost:8000

```

## 2.1 Configure External Services

### FMP 

1. Go to [FMP](https://site.financialmodelingprep.com/) and log in (create a free account if you don't have one).

2. Get the free API key.

3. In the .env file, place the FMP API key.

```
FM_API_KEY=your_fmp_api_key_here
```

### Tavily

1. Go to [Tavily](https://www.tavily.com/) and log in (create a free account if you don't have one).

2. Get the free API key.

3. In the .env file, place the Tavily API key.

```
TAVILY_API_KEY=your_tavily_api_key_here
```

### GEMINI

1. Go to [Google AI Studio](https://aistudio.google.com/) and log in.

2. Get the free API key.

3. In the .env file, place the Tavily API key.

```
GEMINI_API_KEY=your_gemini_api_key_here
```

### MongoDB (Database)

1. Go to [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) and log in (create a free account if you don't have one).

2. Create a free cluster.

3. In the cluster dashboard, click **Connect** â†’ **Connect your application**.

4. Copy the connection string provided. Example:
```
mongodb+srv://<username>:<password>@cluster0.abcd.mongodb.net/<dbname>?retryWrites=true&w=majority
```

For more details, check out the [MongoDB documentation](https://www.mongodb.com/docs/manual/reference/connection-string/).

### Redis (Cache / Broker)

1. Go to [Redis Cloud](https://redis.com/cloud/overview/) and sign in (create a free account if needed).

2. Create a free database (recommended for development).

3. In the dashboard, open your database and click **Connect**.

4. Choose **Connect with Client**, and in the language dropdown, select **Python**.

5. Copy the provided details:
- Host
- Port
- Username (often default)
- Password

6. Paste them into your `.env` file under the Redis section.

For more details, check out the [Redis Cloud documentation](https://cloud.redis.io/#/add-subscription/essential).

> **Note**: You can use `.env.example` as a template if it exists in the repository.


#### 3. Backend Setup

**Step 3.1: Install UV Package Manager**

UV is a fast Python package installer. Install it using:

```bash
# On macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# On Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.sh | iex"

# Alternative: Install via pip
pip install uv
```

**Step 3.2: Create Virtual Environment**

```bash
# Create virtual environment with Python 3.11
uv venv --python 3.11

# Activate virtual environment
# On macOS/Linux:
source .venv/bin/activate

# On Windows:
# .venv\Scripts\activate
```

**Step 3.3: Install Dependencies**

```bash
uv pip install -r requirements.txt
```

**Step 3.4: Start Backend Server**

```bash
# Run the FastAPI server with auto-reload
uvicorn src.backend.app:app

# Alternative: If you're already in src/backend directory
uvicorn app:app
```

The backend will be available at [http://localhost:8000](http://localhost:8000)

#### 4. Frontend Setup

**Step 4.1: Navigate to Frontend Directory**

```bash
# Open a new terminal window/tab and navigate to frontend
cd src/frontend
```

**Step 4.2: Install Dependencies**

```bash
# Install Node.js dependencies
npm install --legacy-peer-deps

# Alternative: Use yarn if preferred
# yarn install
```

**Step 4.3: Configure Environment**

```bash
# Create frontend environment file
echo 'NEXT_PUBLIC_BASE_URL="http://localhost:8000"' > .env.local
```

**Step 4.4: Start Frontend Server**

```bash
# Start Next.js development server
npm run dev

# Alternative commands
# npm start (for production build)
# npm run build (to create production build)
```

The frontend will be available at [http://localhost:3000](http://localhost:3000)

### Docker Setup

For a containerized setup that handles both backend and frontend:

**Option 1: Quick Start**

```bash
# Build and run all services
docker compose -f docker/docker-compose.yml up --build

# Run in detached mode
docker compose -f docker/docker-compose.yml up --build -d
```

<!-- **Option 2: Individual Services**

```bash
# Build only backend
docker compose -f docker/docker-compose.yml build backend

# Build only frontend  
docker compose -f docker/docker-compose.yml build frontend

# Start specific service
docker compose -f docker/docker-compose.yml up backend
``` -->

**Stopping Docker Services**

```bash
# Stop all services
docker compose -f docker/docker-compose.yml down

# Stop and remove volumes
docker compose -f docker/docker-compose.yml down -v
```

## Configuration

### Backend Configuration

The backend can be configured through environment variables:

| Variable | Description |
|----------|-------------|
| `GEMINI_API_KEY` | Gemini API key for LLM |
| `TAVILY_API_KEY` | Tavily API key for search |
| `FMP_API_KEY` | Financial Modeling Prep API key  |

* LLM models can be configured in this file: src/ai/llm/config.py

### Frontend Configuration

The frontend uses these environment variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `NEXT_PUBLIC_BASE_URL` | Backend API URL | `http://localhost:8000` |
| `NEXT_PUBLIC_APP_NAME` | Application name | `TheNZT` |

## Usage

### Getting Started

1. **Ensure both servers are running**:
   - Backend at [http://localhost:8000](http://localhost:8000)
   - Frontend at [http://localhost:3000](http://localhost:3000)

2. **Open your browser** and navigate to [http://localhost:3000](http://localhost:3000)

3. **Register or log in**:
   - For new users, during registration, after entering name, email, and password, an OTP will be generated and displayed in the console for verification.
   - Once verified, you can log in and start asking finance-related queries.

4. **Start asking finance-related topics.**

### Example Queries

**Stock Information**
```
What is the latest stock price for Apple?
Get me the current market cap of Tesla
Show me the P/E ratio for Microsoft
```

**Market Analysis**
```
Summarize recent market trends
What are the top gainers today?
Analyze the tech sector performance this week
```

**Company Financials**
```
Get the quarterly financials for Tesla Inc.
What is Amazon's revenue growth rate?
Compare the debt-to-equity ratio of Apple vs Microsoft
```

**Market Research**
```
What are the upcoming earnings announcements?
Analyze the cryptocurrency market trends
Get me news about renewable energy stocks
```

## Project Structure

```
insight-bot/
â”œâ”€â”€ .venv/                        # Python virtual environment
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architectures/
â”‚   â”œâ”€â”€ graphs/
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ individual_agents/
â”‚   â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ tools/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai/                        
â”‚   â”‚   â”œâ”€â”€ agent_prompts/
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ coding_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_comparison_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ db_search_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ executor_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fast_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ finance_data_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ intent_detector.py
â”‚   â”‚   â”‚   â”œâ”€â”€ manager_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ map_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ planner_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ response_generator_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment_analysis_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ social_media_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ task_validator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ validation_agent.py
â”‚   â”‚   â”‚   â””â”€â”€ web_search_agent.py
â”‚   â”‚   â”œâ”€â”€ ai_schemas/
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_states.py
â”‚   â”‚   â”‚   â”œâ”€â”€ structured_responses.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tool_structured_input.py
â”‚   â”‚   â”‚   â””â”€â”€ validation_utils.py
â”‚   â”‚   â”œâ”€â”€ chart_bot/
â”‚   â”‚   â”‚   â”œâ”€â”€ old/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ financial_tool.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ generate_related_qn.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_react_agent.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ moving_average.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ price_change.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ relative_strength.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tavily_search.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ volatility.py
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ model.py
â”‚   â”‚   â”œâ”€â”€ stock_prediction/
â”‚   â”‚   â”‚   â”œâ”€â”€ stock_prediction_functions.py
â”‚   â”‚   â”‚   â””â”€â”€ stock_prediction.py
â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”‚   â”œâ”€â”€ finance_scraper_utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_gen_tool_system_prompts.py
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_gen_tool.py
â”‚   â”‚   â”‚   â”œâ”€â”€ internal_db_tools.py
â”‚   â”‚   â”‚   â”œâ”€â”€ map_tools.py
â”‚   â”‚   â”‚   â”œâ”€â”€ social_media_tools.py
â”‚   â”‚   â”‚   â”œâ”€â”€ web_search_tools.py
â”‚   â”‚   â”‚   â””â”€â”€ insight_graph.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ backend/                    
â”‚   â”‚   â”œâ”€â”€ api/                    
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ core/                   
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ api_limit.py        
â”‚   â”‚   â”‚   â”œâ”€â”€ limiter.py          
â”‚   â”‚   â”‚   â””â”€â”€ JWT.py              
â”‚   â”‚   â”œâ”€â”€ db/                      
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ mongodb.py
â”‚   â”‚   â”‚   â”œâ”€â”€ qdrant.py
â”‚   â”‚   â”‚   â””â”€â”€ filestorage.py
â”‚   â”‚   â”œâ”€â”€ models/                 
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ app_io_schemas.py   
â”‚   â”‚   â”œâ”€â”€ utils/                  
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_comm.py       
â”‚   â”‚   â”‚   â”œâ”€â”€ api_utils.py        
â”‚   â”‚   â”‚   â”œâ”€â”€ async_runner.py     
â”‚   â”‚   â”‚   â”œâ”€â”€ export_utils.py     
â”‚   â”‚   â”‚   â”œâ”€â”€ helper_functions.py 
â”‚   â”‚   â”‚   â””â”€â”€ utils.py            
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py                  
â”‚   â””â”€â”€ frontend/     
â”‚       â”œâ”€â”€ .next/
â”‚       â”œâ”€â”€ node_modules/
â”‚       â”œâ”€â”€ public/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/
â”‚       â”‚   â”‚   â”œâ”€â”€ (auth)/
â”‚       â”‚   â”‚   â”œâ”€â”€ (chats)/
â”‚       â”‚   â”‚   â”œâ”€â”€ (dashboard)/
â”‚       â”‚   â”‚   â”œâ”€â”€ map/
â”‚       â”‚   â”‚   â”œâ”€â”€ onboarding/
â”‚       â”‚   â”‚   â”œâ”€â”€ stock_details/
â”‚       â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚       â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚       â”‚   â”‚   â””â”€â”€ styles.css
â”‚       â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â”‚   â”œâ”€â”€ canvas/
â”‚       â”‚   â”‚   â”œâ”€â”€ charts/
â”‚       â”‚   â”‚   â”œâ”€â”€ chat/
â”‚       â”‚   â”‚   â”œâ”€â”€ icons/
â”‚       â”‚   â”‚   â”œâ”€â”€ layout/
â”‚       â”‚   â”‚   â”œâ”€â”€ maps/
â”‚       â”‚   â”‚   â”œâ”€â”€ markdown/
â”‚       â”‚   â”‚   â”œâ”€â”€ Modals/
â”‚       â”‚   â”‚   â””â”€â”€ ui/
â”‚       â”‚   â”‚       â”œâ”€â”€ Loader.tsx
â”‚       â”‚   â”‚       â””â”€â”€ tooltip-content.tsx
â”‚       â”‚   â”œâ”€â”€ hooks/
â”‚       â”‚   â”‚   â”œâ”€â”€ use-is-mobile.tsx
â”‚       â”‚   â”‚   â”œâ”€â”€ use-screen.tsx
â”‚       â”‚   â”‚   â”œâ”€â”€ use-toast.ts
â”‚       â”‚   â”‚   â”œâ”€â”€ useMediaQuery.ts
â”‚       â”‚   â”‚   â””â”€â”€ useWindowDimension.tsx
â”‚       â”‚   â””â”€â”€ lib/
â”‚       â”‚       â”œâ”€â”€ formatter.ts
â”‚       â”‚       â”œâ”€â”€ mapData.ts
â”‚       â”‚       â”œâ”€â”€ store.ts
â”‚       â”‚       â”œâ”€â”€ types.ts
â”‚       â”‚       â”œâ”€â”€ useDebounce.ts
â”‚       â”‚       â”œâ”€â”€ utils.ts
â”‚       â”‚       â”œâ”€â”€ services/
â”‚       â”‚       â”‚   â”œâ”€â”€ ApiServices.ts
â”‚       â”‚       â”‚   â”œâ”€â”€ axiosInstance.ts
â”‚       â”‚       â”‚   â”œâ”€â”€ endpoints.ts
â”‚       â”‚       â”‚   â””â”€â”€ stockData.ts
â”‚       â”‚       â”œâ”€â”€ store/
â”‚       â”‚       â”‚   â”œâ”€â”€ useSessionHistory.ts
â”‚       â”‚       â”‚   â””â”€â”€ useZustandStore.ts
â”‚       â”‚       â”œâ”€â”€ types/
â”‚       â”‚       â”‚   â”œâ”€â”€ auth-types.ts
â”‚       â”‚       â”‚   â”œâ”€â”€ chart-data.ts
â”‚       â”‚       â”‚   â”œâ”€â”€ map-view.ts
â”‚       â”‚       â”‚   â””â”€â”€ plotly-types.ts
â”‚       â”‚       â””â”€â”€ utils/
â”‚       â”‚           â”œâ”€â”€ auth.ts
â”‚       â”‚           â”œâ”€â”€ date.ts
â”‚       â”‚           â”œâ”€â”€ getCookie.ts
â”‚       â”‚           â”œâ”€â”€ motion.ts
â”‚       â”‚           â”œâ”€â”€ pagination.ts
â”‚       â”‚           â”œâ”€â”€ plotly.ts
â”‚       â”‚           â”œâ”€â”€ session.ts
â”‚       â”‚           â””â”€â”€ utility.ts
â”‚       â”œâ”€â”€ .env.example
â”‚       â”œâ”€â”€ .gitignore
â”‚       â”œâ”€â”€ .prettierignore
â”‚       â”œâ”€â”€ .prettierrc
â”‚       â”œâ”€â”€ components.json
â”‚       â”œâ”€â”€ eslint.config.mjs
â”‚       â”œâ”€â”€ next-env.d.ts
â”‚       â”œâ”€â”€ next.config.js
â”‚       â”œâ”€â”€ package-lock.json
â”‚       â”œâ”€â”€ package.json
â”‚       â”œâ”€â”€ postcss.config.mjs
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ tailwind.config.ts
â”‚       â”œâ”€â”€ tsconfig.json
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ .env.example                 
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## API Documentation

Once the backend is running, you can access:

- **Interactive API Documentation**: [http://localhost:8000/docs](http://localhost:8000/docs) (Swagger UI)
- **Alternative API Docs**: [http://localhost:8000/redoc](http://localhost:8000/redoc) (ReDoc)
- **API Schema**: [http://localhost:8000/openapi.json](http://localhost:8000/openapi.json)

### Key Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/chat` | Send finance query |
| `GET` | `/api/health` | Health check |
| `GET` | `/api/status` | System status |

## Troubleshooting

### Common Issues

**Backend Issues**

1. **Port 8000 already in use**
   ```bash
   # Kill process using port 8000
   sudo lsof -t -i tcp:8000 | xargs kill -9
   
   # Or use different port
   uvicorn app:app --port 8001
   ```

2. **Missing dependencies**
   ```bash
   # Reinstall dependencies
   uv pip install -r requirements.txt --force-reinstall
   ```

3. **API key errors**
   ```bash
   # Verify .env file exists and has correct keys
   cat .env | grep API_KEY
   ```

**Frontend Issues**

1. **Port 3000 already in use**
   ```bash
   # Use different port
   npm run dev -- -p 3001
   ```

2. **Node modules issues**
   ```bash
   # Clean and reinstall
   rm -rf node_modules package-lock.json
   npm install --legacy-peer-deps
   ```

3. **Environment variable not loading**
   ```bash
   # Ensure .env.local exists in frontend directory
   ls -la src/frontend/.env.local
   ```

**Docker Issues**

1. **Build failures**
   ```bash
   # Clean rebuild
   docker compose -f docker/docker-compose.yml down
   docker system prune -f
   docker compose -f docker/docker-compose.yml up --build
   ```

### Getting Help

- **GitHub Issues**: Report bugs and request features
- **Discussions**: Ask questions and share ideas
- **Documentation**: Check the docs folder for detailed guides

## License

This project is licensed under the terms of the [MIT License](LICENSE).

---

For more information, visit our [documentation](docs/) or check out the [contributing guidelines](CONTRIBUTING.md).
